# CC6204 Deep Learning

Deep Learning es un curso electivo de pre y postgrado del departamento de Ciencias de la Computación de la [Universidad de Chile](http://ingenieria.uchile.cl/). El objetivo del curso es introducir a los estudiantes al área de aprendizaje basado en red neuronales profundas, comúnmente conocida como Deep Learning. Las técnicas utilizadas en esta área han resultado fundamentales en los últimos avances en Inteligencia Artificial en particular tareas como procesamiento de lenguaje natural y visión computacional. Durante el curso los estudiantes serán expuesto a la teoría detrás de los modelos de Deep Learning, comprenderán el funcionamiento, los usos posibles, y serán capaces de construir y entrenar modelos que permitan solucionar problemas reales.

---

## Unidad 1. Fundamentos

### Capítulo 1. Introducción a redes neuronales modernas. 

Los contenidos de este capítulo son:

* Perceptrón, perceptrón multi- capa, funciones de activación, no linealidad.
* Redes neuronales, cómo computan, qué no pueden computar, representación tensorial. 
* Álgebra tensorial y cálculo tensorial. 
* Funciones de error/pérdida y entrenamiento por descenso de gradiente. 
* Grafos de computación y el algoritmo de BackPropagation.

Bibliografía recomendada <sup>[1](#DeepLearningBook)</sup>:

* [Algebra lineal](http://www.deeplearningbook.org/contents/part_basics.html)
* [Probabilidades y teoría de la información](http://www.deeplearningbook.org/contents/prob.html)
* [Deep Feedforward Networks](http://www.deeplearningbook.org/contents/mlp.html)

Tutoriales recomendados:
* [Quickstart tutorial numpy](https://docs.scipy.org/doc/numpy-dev/user/quickstart.html)
* [DeepLearning con PyTorch en 60 minutos](http://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)

Videos de las clases:
* [Clase 1: Peceptrón, funciones de activación, perceptrón multicapa, redes feed forward (FF), expresividad de redes FF](https://www.youtube.com/watch?v=oCGB8wVej-I)
* [Clase 2: Función de error/pérdida y entrenamiento por descenso del gradiente](https://www.youtube.com/watch?v=tONNKS2En9c)
* [Clase 3: Algoritmos de backpropagation](https://www.youtube.com/watch?v=KXqSt4-8l_E)

### Capítulo 2. Algoritmos de aprendizaje, regularización y optimización.

Los contenidos de este capítulo son:

* Descenso de gradiente estocástico. 
* Inicialización de parámetros, normalización, normalización de paquetes. 
* Aprendizaje adaptativo 
* Dropout 
* Penalización de parámetros

Bibliografía recomendada <sup>[1](#DeepLearningBook)</sup>:

* [Regularización](http://www.deeplearningbook.org/contents/regularization.html)
* [Optimización](http://www.deeplearningbook.org/contents/optimization.html)

### Capítulo 3. Aspectos prácticos de entrenamiento y aprendizaje.

Los contenidos de este capítulo son:

* Conceptos clásicos de aprendizaje de máquina. 
* Métricas de eficiencia, baselines, overfitting, underfitting. 
* Búsqueda y selección de hiperparámetros. 
* Técnicas de debugging 
* Uso de GPUs en el entrenamiento 
* Organizando una solución basada en Machine Learning y Deep Learning.

Bibliografía recomendada <sup>[1](#DeepLearningBook)</sup>:

* [Metodología práctica](http://www.deeplearningbook.org/contents/guidelines.html)

---

## Unidad 2. Redes convolucionales y aplicaciones.

### Capitulo 4. Redes convolucionales

Los contenidos de este capítulo son:

* Redes Neuronales convolucionales 
* Relación de CNN con el modelo biológico 
* Estudio de arquitecturas CNN del estado del arte. 
* Caffe y TensorFlow 
* Visualización de modelos CNN. 
* Búsqueda por Similitud usando Deep Features. 
* Hashing de vectores de características usando Deep Learning. 
* Class Activation Mapping. 
* Modelos de Deep Learning para Detección de Objetos (imágenes) 
* Modelos de Deep Learning para Segmentación de imágenes.

Bibliografía recomendada <sup>[1](#DeepLearningBook)</sup>:

* [Redes convolucionales](http://www.deeplearningbook.org/contents/convnets.html)
* [Aplicaciones](http://www.deeplearningbook.org/contents/applications.html)

---

## Unidad 3. Redes recurrentes y aplicaciones.

### Capítulo 5. Redes recurrentes.

Los contenidos de este capítulo son:

* Redes recurrentes 
* Backpropagation en el tiempo 
* Redes recurrentes bidireccionales. 
* Dependencias temporales a largo plazo. 
* Modelos con memoria externa explícita. 
* Aplicaciones en procesamiento de lenguaje natural y otras aplicaciones basadas en secuencias.

Bibliografía recomendada <sup>[1](#DeepLearningBook)</sup>:

* [Modelos secuenciales y redes recurrentes](http://www.deeplearningbook.org/contents/rnn.html)
* [Aplicaciones](http://www.deeplearningbook.org/contents/applications.html)

---

## Unidad 4. Tópicos avanzados.

### Capítulo 6. Tópicos avanzados.

En este capítulo se elegirán de entre siguientes contenidos:

* Introducción a los Modelos Generativos.
* Autoencoders
* Autoencoder Variacionales
* Generative Adversarial Networks
* Neural Turing Machine (NeuralTM).
* Computación Neuronal Derivable (DNC).
* CapsNet.

Bibliografía recomendada <sup>[1](#DeepLearningBook)</sup>:

* [Autoencoders](http://www.deeplearningbook.org/contents/autoencoders.html)
* [Modelos generativos](www.deeplearningbook.org/contents/generative_models.html)

---



<a name="DeepLearningBook">1</a>: El libro [Deep Learning](http://www.deeplearningbook.org/) será utilzado como guía durante gran parte del curso.
