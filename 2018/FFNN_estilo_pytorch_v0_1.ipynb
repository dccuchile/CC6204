{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FFNN_estilo_pytorch_v0.1",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "gYJp1WdDmYT9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CC6204 - 2018 Universidad de Chile\n",
        "## Código de Red Neuronal simple estilo pytorch\n",
        "El siguiente código se entrega a modo de ejemplo para crear una red neuronal Feed Forward de 2 capas escondidas y predicción binaria. Todos los parámetros de la red se crean a mano, pero dejamos que pytorch calcule los gradientes que luego usamos en el loop principal de entrenamiento. Incluye el soporte para GPUs.\n",
        "\n",
        "La idea es que el código sirva para aprender la arquitectura general de red+entrenamiento+predicción usando las clases abstractas de pytorch además de las utilidades que entrega para crear optimizadores y objetos para cargar datos de manera eficiente. \n",
        "\n",
        "El código muestra varias cosas:\n",
        "\n",
        "*   uso de funciones de activación y pérdida en `torch.nn` (\n",
        "[`torch.nn.Sigmoid`](http://pytorch.org/docs/master/nn.html#torch.nn.Sigmoid),\n",
        "[`torch.nn.Tanh`](http://pytorch.org/docs/master/nn.html#torch.nn.Tanh) y\n",
        "[`torch.nn.BCELoss`](http://pytorch.org/docs/master/nn.html#torch.nn.BCELoss)),\n",
        "*   el estilo pytorch de definir redes (heredando de [`torch.nn.Module`](http://pytorch.org/docs/master/nn.html#torch.nn.Module)),\n",
        "*   el estilo pytorch de definir optimizadores (heredando de [`torch.optim.Optimizer`](http://pytorch.org/docs/master/optim.html)),\n",
        "*   la creación de datasets (heredando de [`torch.utils.data.Dataset`](http://pytorch.org/docs/master/data.html)) y el uso de dataloaders ([`torch.utils.data.DataLoader`](http://pytorch.org/docs/master/data.html)).\n",
        "\n",
        "(Pensado para correr en [Colaboratory](http://colab.research.google.com))\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "PVvSzJNOdR73",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision\n",
        "!pip install -q ipdb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_12quP2FYkhB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import sys\n",
        "import time\n",
        "import ipdb\n",
        "\n",
        "# Estos dos imports son para clases útiles.\n",
        "from torch.nn import Parameter\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Genera una semilla fija para que los experimentos sea repetibles.\n",
        "t_cg = torch.manual_seed(1547)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XTmy1fMRkqwv",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "10b972f8-f667-407b-dd21-173676416e18",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1520612518522,
          "user_tz": 180,
          "elapsed": 635,
          "user": {
            "displayName": "Jorge Perez",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "107068936185859088499"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Chequeamos si hay acceso a la GPU\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mRmwQVQtdahC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# torch.nn tiene varias funciones de activación y de pérdida\n",
        "# que se pueden utilizar directamente. No es necesario programar\n",
        "# las más comunes.\n",
        "\n",
        "# Funciones de activación\n",
        "sig = torch.nn.Sigmoid()\n",
        "tanh = torch.nn.Tanh()\n",
        "\n",
        "# Función de pérdida (Binary Cross Entropy Loss)\n",
        "cross_ent = torch.nn.BCELoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XRDsrKnAdfm8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Las redes (modelos en general) deben heredar desde torch.nn.Module\n",
        "class FFNN2C(torch.nn.Module):\n",
        "  \n",
        "  # En el inicializador debemos crear los parámetros de la red\n",
        "  # así como todo lo necesario para hacer las predicciones.\n",
        "  def __init__(self, d0, d1, d2):\n",
        "    super(FFNN2C, self).__init__()\n",
        "    \n",
        "    # Un 'Parameter' es un caso particular de 'Variable' y hace que los\n",
        "    # parámetros se agreguen automáticamente al iterador .parameters()\n",
        "    # de la red.\n",
        "    self.W1 = Parameter(torch.randn(d0,d1))\n",
        "    self.c1 = Parameter(torch.zeros(d1))\n",
        "    self.W2 = Parameter(torch.randn(d1,d2))\n",
        "    self.c2 = Parameter(torch.zeros(d2))\n",
        "    self.W3 = Parameter(torch.randn(d2,1))\n",
        "    \n",
        "  def forward(self, x):\n",
        "    u1 = x.mm(self.W1).add(self.c1)\n",
        "    h1 = tanh(u1)\n",
        "    u2 = h1.mm(self.W2).add(self.c2)\n",
        "    h2 = sig(u2)\n",
        "    u3 = h2.mm(self.W3)\n",
        "    y_pred = sig(u3)\n",
        "    \n",
        "    return y_pred\n",
        "  \n",
        "# Las deribadas necesarias para el Back Propagation se calculan \n",
        "# de manera automática con Module.backward()!!!! :-)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1FP105N9alSw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Los optimizadores deben heredar desde torch.optim.Optimizer\n",
        "\n",
        "# Acá definimos uno muy simple de descenso de gradiente simple.\n",
        "class DG(torch.optim.Optimizer):\n",
        "  def __init__(self, params, lr):\n",
        "    # Con esta llamada los parámetros quedan en \n",
        "    # self.param_groups[i]['params']\n",
        "    super(DG, self).__init__(params, {'lr':lr})\n",
        "  \n",
        "  def step(self):\n",
        "    # Este optimizador usa un solo conjunto de paramteros.\n",
        "    # Para un optimizador con más grupos de parámetros se puede\n",
        "    # iterar sobre self.param_groups\n",
        "    params = self.param_groups[0]['params']\n",
        "    lr = self.param_groups[0]['lr']\n",
        "    for p in params:\n",
        "        if p.grad is None:\n",
        "          continue\n",
        "        p.data -= p.grad.data * lr\n",
        "        \n",
        "# pytorch tiene varios otros optimizadores ya programados que se\n",
        "# pueden utilizar (incluído el torch.optim.SGD similar al DGB que \n",
        "# acabamos de programar)."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BIC55CMtvu7o",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Finalmente para cargar los datos, pytorch provee varias clases\n",
        "# que simplifican el proceso. Las mas importantes son Dataset (clase\n",
        "# abstracta) y DataLoader. \n",
        "# A continuación creamos un Dataset aleatorio.\n",
        "class RandomDataSet(Dataset):\n",
        "  def __init__(self, N, f):\n",
        "    R_N_f = torch.rand(N,f)\n",
        "    self.X = torch.bernoulli(R_N_f)\n",
        "    R_N_1 = torch.rand(N,1)\n",
        "    self.Y = torch.bernoulli(R_N_1)\n",
        "    \n",
        "  # Debemos definir __len__ para retornar la cantidad de datos/ejemplos\n",
        "  # en nuestro dataset.\n",
        "  def __len__(self):\n",
        "    return self.X.size()[0]\n",
        "\n",
        "  # Debemos definir __getitem__ para retornar el i-ésimo ejemplo en nuestro\n",
        "  # dataset. En este caso los datos los sacamos de la memoria principal,\n",
        "  # pero podríamos sacarlos desde la web, el disco, o incluso irlos generando\n",
        "  # a medida que los van solicitando.\n",
        "  def __getitem__(self, i):\n",
        "    return self.X[i], self.Y[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uw3OewBt55St",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Ya tenemos todo listo para definir nuestra iteración principal de\n",
        "# entrenamiento de la red.\n",
        "def ejemplo_FFNN(dataset, features, d1=200, d2=300, lr=0.06, b=1,\n",
        "                 epochs=10, run_in_GPU=False, report_every=1,\n",
        "                 verbose=False, cheq_grad=False,\n",
        "                 debug=False):\n",
        "  \n",
        "  # Crea la red\n",
        "  red = FFNN2C(features,d1,d2)\n",
        "  # Como heredamos desde torch.nn.Module, pasar todos los parámetros de la\n",
        "  # red a la GPU es muy simple, simplemente usando .cuda().\n",
        "  if run_in_GPU:\n",
        "    red = red.cuda()\n",
        "  \n",
        "  # Crea el optimizador de parametros para la red.\n",
        "  optimizador = DG(red.parameters(), lr)\n",
        "  \n",
        "  # Usamos DataLoader para crear un iterador sobre el dataset. En este\n",
        "  # caso usamos un batch de tamaño 'b' y le pedimos que desordene los datos.\n",
        "  batches = DataLoader(dataset, batch_size=b, shuffle=True)  \n",
        "\n",
        "  # Comienzo del entrenamiento.\n",
        "  tiempo_epochs = 0\n",
        "  for e in range(1,epochs+1):\n",
        "    inicio_epoch = time.clock()\n",
        "    \n",
        "    for x, y in batches:\n",
        "      x = Variable(x, requires_grad=False)\n",
        "      y = Variable(y, requires_grad=False)\n",
        "      \n",
        "      # Pásalos a la GPU si fuera necesario.\n",
        "      if run_in_GPU:\n",
        "        x = x.cuda()\n",
        "        y = y.cuda()\n",
        "\n",
        "      # Usa la red para computar la predicción.\n",
        "      y_pred = red(x)\n",
        "\n",
        "      # Calcula la función de pérdida.\n",
        "      L = cross_ent(y_pred, y)\n",
        "        \n",
        "      # Vacía los gradientes.\n",
        "      red.zero_grad()\n",
        "      # Vaciar los gradientes es muy importante pues pytorch nos permite\n",
        "      # tener control total sobre los gradientes que vamos computando y\n",
        "      # por ejemplo acumularlos desde distintas redes.\n",
        "\n",
        "      # Computa la pasada hacia atrás.\n",
        "      L.backward()\n",
        "\n",
        "      # Computa un paso del optimizador (modifica los pesos).\n",
        "      optimizador.step()\n",
        "\n",
        "      # Listo! :-)\n",
        "    tiempo_epochs += time.clock() - inicio_epoch\n",
        "    \n",
        "    if e % report_every == 0:\n",
        "      # Podemos ir chequeando la certeza de las predicciones hasta el momento.\n",
        "      # En este caso las chequeamos sobre todos los ejemplos.\n",
        "      # Ojo: no es lo habitual hacerlo así pues se nos puede llenar la memoria\n",
        "      # si cargamos todos los datos juntos. Esto es solo demostrativo.\n",
        "      X = data.X\n",
        "      Y = data.Y\n",
        "      \n",
        "      # Pásalo a la GPU si fuera necesario\n",
        "      if run_in_GPU:\n",
        "        X = X.cuda()\n",
        "        Y = Y.cuda()\n",
        "\n",
        "      Xv = Variable(X)\n",
        "      Yv = Variable(Y)    \n",
        "      Y_PREDv = red(Xv)\n",
        "\n",
        "      L = cross_ent(Y_PREDv, Yv).data[0]\n",
        "\n",
        "      # Convierte las predicciones en 0 o 1 dependiendo de si la probabilidad\n",
        "      # es mayor o igual a 0.5.\n",
        "      Y_PRED = (Y_PREDv.data >= 0.5).float()    \n",
        "      correctos = torch.sum(Y_PRED == Y)\n",
        "      acc = float(correctos) / float(N) * 100\n",
        "\n",
        "      sys.stdout.write(\n",
        "          '\\rEpoch:{0:03d}'.format(e) + ' Acc:{0:.2f}%'.format(acc)\n",
        "          + ' Loss:{0:.4f}'.format(L) \n",
        "          + ' Tiempo/epoch:{0:.3f}s'.format(tiempo_epochs/e))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qnwBHxk4jbfT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 30
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "91f0e6ab-a86b-40a3-90b0-b4564baeb61c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1520614973429,
          "user_tz": 180,
          "elapsed": 13832,
          "user": {
            "displayName": "Jorge Perez",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "107068936185859088499"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Ahora la probamos.\n",
        "N = 5000 \n",
        "f = 300\n",
        "data = RandomDataSet(N,f)\n",
        "ejemplo_FFNN(data,f,b=32,d1=300,d2=400,epochs=30,run_in_GPU=False)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:030 Acc:99.98% Loss:0.0164 Tiempo/epoch:0.332s"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "txp_Mgzaj3v0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}